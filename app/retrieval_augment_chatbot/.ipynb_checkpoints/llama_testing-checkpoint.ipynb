{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92eb9267-6dd1-4169-a4ba-25736b0117c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fcd5c3f-25d5-4b03-8ae1-aa771f330a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.9/dist-packages (0.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface_hub) (4.6.3)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface_hub) (23.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface_hub) (2.28.2)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.9/dist-packages (from huggingface_hub) (4.64.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from huggingface_hub) (5.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface_hub) (3.9.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->huggingface_hub) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface_hub) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface_hub) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->huggingface_hub) (2019.11.28)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2731c19a-d984-4178-bcdf-b647b20cfb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b690e75-02c2-4b42-ae74-319935c908d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = hf_hub_download(repo_id=\"TheBloke/llama-13b-supercot-GGML\", filename=\"llama-13b-supercot.ggmlv3.q4_0.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ebf5baf-9990-424d-ac99-b3add7989495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e8a2dc1f464c919e1d5cbfedb5ecfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦).ggmlv3.q3_K_S.bin\";:   0%|          | 0.00/14.0G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = hf_hub_download(repo_id=\"TheBloke/WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGML\", filename=\"WizardLM-Uncensored-SuperCOT-Storytelling.ggmlv3.q3_K_S.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4baf6f04-61e5-4b39-b2ed-bbb3fc105a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/root/.cache/huggingface/hub/models--TheBloke--WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGML/snapshots/dfc28ffcd7863fca495ea5b29a6ffd487937ccd0/WizardLM-Uncensored-SuperCOT-Storytelling.ggmlv3.q3_K_S.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "158c56d8-7f5c-44c9-9a1b-d9a8ac356968",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ggml_init_cublas: found 1 CUDA devices:\n",
      "  Device 0: Quadro M4000\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05d83993-f0e4-445b-8f26-9f39a6683c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /root/.cache/huggingface/hub/models--TheBloke--WizardLM-Uncensored-SuperCOT-StoryTelling-30B-GGML/snapshots/dfc28ffcd7863fca495ea5b29a6ffd487937ccd0/WizardLM-Uncensored-SuperCOT-Storytelling.ggmlv3.q3_K_S.bin\n",
      "llama_model_load_internal: format     = ggjt v3 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32001\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 6656\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 52\n",
      "llama_model_load_internal: n_layer    = 60\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 11 (mostly Q3_K - Small)\n",
      "llama_model_load_internal: n_ff       = 17920\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 30B\n",
      "llama_model_load_internal: ggml ctx size =    0.13 MB\n",
      "llama_model_load_internal: using CUDA for GPU acceleration\n",
      "llama_model_load_internal: mem required  = 10592.78 MB (+ 3124.00 MB per state)\n",
      "llama_model_load_internal: allocating batch_size x 1 MB = 512 MB VRAM for the scratch buffer\n",
      "llama_model_load_internal: offloading 23 repeating layers to GPU\n",
      "llama_model_load_internal: offloaded 23/63 layers to GPU\n",
      "llama_model_load_internal: total VRAM used: 5556 MB\n",
      "....................................................................................................\n",
      "llama_init_from_file: kv self size  = 3120.00 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "llm = Llama(model_path=path, n_ctx=2048, n_gpu_layers=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "785bd5f0-6cf2-4076-8678-3a0b979b9a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time = 11247.91 ms\n",
      "llama_print_timings:      sample time =    25.59 ms /    32 runs   (    0.80 ms per token)\n",
      "llama_print_timings: prompt eval time =     0.00 ms /     1 tokens (    0.00 ms per token)\n",
      "llama_print_timings:        eval time = 39544.63 ms /    32 runs   ( 1235.77 ms per token)\n",
      "llama_print_timings:       total time = 39702.54 ms\n"
     ]
    }
   ],
   "source": [
    "output = llm(\"Q: Name the planets in the solar system? A: \", max_tokens=32, echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "224d864d-d86f-4f1a-a2d3-102f61986450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Q: Name the planets in the solar system? A: \\n1. Mercury \\n2. Venus \\n3. Earth \\n4. Mars \\n5. Jupiter \\n6. Sat'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[\"choices\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a41cecc2-39eb-47bb-a396-ffc4ac6cf70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"## Instruction\n",
    "You are a personal assistent that answer user query. You have access to the following tools to help you:\n",
    "\n",
    "- Web Search\n",
    "  - *Description*: Use search engine online to find webpage.\n",
    "  - *Usage*: [web_search(<query>)]\n",
    "  - *Example*: [web_search(\"how to make a cake\")]\n",
    "- Read webpage\n",
    "  - *Description*: Read the content of a webpage. It will be presented to you in markdown format after the raw html is parsed and some elements stripped.\n",
    "  - *Usage*: [read_webpage(<url>)]\n",
    "  - *Example*: [read_webpage(\"https://apple.com/\")]\n",
    "- Finalize your answer\n",
    "  - *Description*: Give your final answer to user, and give **exactly three** suggested followup questions to user.\n",
    "  - *Usage*: [final_ans(<name of subsection with answer>, <name of subsection with followup question>)]\n",
    "  - *Note*: You would have output the required information beforehand already, so here you're just linking to the documents you wrote. See further instruction below.\n",
    "  - *Example*: [final_ans(\"Assistent Answer - How to make a cake\", \"Suggested followup to 'how to make a cake'\")]\n",
    "\n",
    "You should think using the following pattern:\n",
    "\n",
    "*Thought 1*: <your internal thoughts based on current state and your knowledge, then decide on a course of action. Describe verbally your decision but do not output tool use yet.>\n",
    "*Act 1*: <based on your decision in the thought above, output should be a tool use strictly adhering to the formats in \"Usage\". make no other outputs here and no markdown codeblock necessary.>\n",
    "*Observation 1*: <result of tool use will be shown here>\n",
    "\n",
    "This pattern can be repeated (with the number increasing such as *Thought 2*, *Thought 3*, etc. Ditto for Act and Observation) until you arrive at a final answer.\n",
    "\n",
    "An exception to this pattern is when you're ready to give your final answer. You should insert two markdown subsections (level H3, i.e. `###`) before your final Act line. One subsection is the answer to the user, the other is suggested followup questions.\n",
    "\n",
    "For the answer, you should cite the source you used using markdown footnote, eg [^1] next to the sentence using the source, then give reference at the end: [^1] <Webpage title linking to the webpage, using markdown link>\n",
    "\n",
    "The followup should be a markdown unnumbered list, each question as an item, with nothing else in the subsection.\n",
    "\n",
    "To illustrate, here's an example:\n",
    "...\n",
    "*Observation 5*: ...\n",
    "### Assistent Answer - How to make a cake\n",
    "Here's a quick recipe for **Chocolate cake** [^1]:\n",
    "1. Prepare the flour.\n",
    "2. Put chocolate in the flour.\n",
    "3. Cook in oven at 180C for 30 minutes.\n",
    "----\n",
    "[^1]: [Easy cake recipe - Etsy](https://etsy.com/easy-cake)\n",
    "### Suggested followup to 'how to make a cake'\n",
    "- How to make a pancake?\n",
    "- Where can I buy the ingredient?\n",
    "- How about cookie?\n",
    "*Act 5*: [final_ans(\"Assistent Answer - How to make a cake\", \"Suggested followup to 'how to make a cake'\")].\n",
    "\n",
    "## Input\n",
    "Question: Give me a summary of news on debt ceiling in the US.\n",
    "## Output\n",
    "Assistent: Let's think step by step.\n",
    "*Thought 1*: To find news articles about the debt ceiling in the US, I will use Web Search.\n",
    "*Act 1*: [web_search(\"debt ceiling US news\")].\n",
    "*Observation 1*: Search Result:\n",
    "1. US Government in deadlock over debt ceiling dispute\n",
    "https://cnn.com/news/us/politics/debt-ceiling-5gx7u\n",
    "2. Liberals propose uping the debt ceiling for infrastructural investment, stirs objections from Republican\n",
    "https://realnews.org/liberal-infra-debt/28VeKu\n",
    "3. Are we going to have QE again? Worries loom over recent debt ceiling proposal\n",
    "https://editorial.washingtonpost.com/quince-mac/qe-debt\n",
    "4. Reddit - r/Politics Republican's idea of debt ceiling\n",
    "https://reddit.com/r/politics/republican-idea-debt-ceiling-3JcYhE\n",
    "\n",
    "*Thought 2*: To summarize the news articles, I will read the first and most relevant article which is \"US Government in deadlock over debt ceiling dispute\" from CNN.\n",
    "*Act 2*: [read_webpage(\"https://cnn.com/news/us/politics/debt-ceiling-5gx7u\")].\n",
    "*Observation 2*: Webpage content:\n",
    "The democrats party have proposed a new bill in congress to raise the debt ceiling for an expansionary fiscal policy, investing in the US's infrastructure. They believes that with a deep recession predicted by a majority of economists, Keynesian style policy would be necessary to avert disaster. Republican understandably objected vehemetly, saying that this is a betrayal of Americans by going back to the long gone age of QE, which, if passed, they say would results in robbing ordinary American citizen of their wealth and creating a perverse incentive to award lazy people. As the congress is about evenly split on both side, neither party are able to push forward.\n",
    "\n",
    "*Thought 3*: Therefore, the summary of news articles on debt ceiling in the US is that there is a deadlock between Democrats and Republicans over a proposed bill to raise the debt ceiling for infrastructural investment, with Republicans objecting due to concerns about QE. \n",
    "### Assistent News Summary - Debt Ceiling in US\n",
    "The current situation is characterized by a political impasse between Democrats and Republicans regarding a proposed bill to increase the debt ceiling for infrastructure investment. While the Democrats believe that this policy would help avert a recession, Republicans oppose it due to concerns about the potential impact on ordinary Americans and the incentives it might create. As of now, neither party has been able to make significant progress in resolving the issue. [^1]\n",
    "----\n",
    "[^1]  - CNN: https://cnn.com/news/us/politics/debt-ceiling-5gx7u\n",
    "### Suggested followup\n",
    "- How does the debt ceiling affect the US economy?\n",
    "- What are the potential consequences of not raising the debt ceiling?\n",
    "- How has the debt ceiling been handled in other countries?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa08129c-4d61-43b8-a311-b970ba3c8775",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time = 27406.39 ms\n",
      "llama_print_timings:      sample time =    30.36 ms /    42 runs   (    0.72 ms per token)\n",
      "llama_print_timings: prompt eval time =  8832.81 ms /    46 tokens (  192.02 ms per token)\n",
      "llama_print_timings:        eval time = 66987.44 ms /    41 runs   ( 1633.84 ms per token)\n",
      "llama_print_timings:       total time = 85346.19 ms\n"
     ]
    }
   ],
   "source": [
    "myOut = llm(prompt, max_tokens=200, stop=[\"*Observation\"], echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5201d8de-b956-4ab9-91d1-1d6e7041d3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Instruction\n",
      "You are a personal assistent that answer user query. You have access to the following tools to help you:\n",
      "\n",
      "- Web Search\n",
      "  - *Description*: Use search engine online to find webpage.\n",
      "  - *Usage*: [web_search(<query>)]\n",
      "  - *Example*: [web_search(\"how to make a cake\")]\n",
      "- Read webpage\n",
      "  - *Description*: Read the content of a webpage. It will be presented to you in markdown format after the raw html is parsed and some elements stripped.\n",
      "  - *Usage*: [read_webpage(<url>)]\n",
      "  - *Example*: [read_webpage(\"https://apple.com/\")]\n",
      "- Finalize your answer\n",
      "  - *Description*: Give your final answer to user, and give **exactly three** suggested followup questions to user.\n",
      "  - *Usage*: [final_ans(<name of subsection with answer>, <name of subsection with followup question>)]\n",
      "  - *Note*: You would have output the required information beforehand already, so here you're just linking to the documents you wrote. See further instruction below.\n",
      "  - *Example*: [final_ans(\"Assistent Answer - How to make a cake\", \"Suggested followup to 'how to make a cake'\")]\n",
      "\n",
      "You should think using the following pattern:\n",
      "\n",
      "*Thought 1*: <your internal thoughts based on current state and your knowledge, then decide on a course of action. Describe verbally your decision but do not output tool use yet.>\n",
      "*Act 1*: <based on your decision in the thought above, output should be a tool use strictly adhering to the formats in \"Usage\". make no other outputs here and no markdown codeblock necessary.>\n",
      "*Observation 1*: <result of tool use will be shown here>\n",
      "\n",
      "This pattern can be repeated (with the number increasing such as *Thought 2*, *Thought 3*, etc. Ditto for Act and Observation) until you arrive at a final answer.\n",
      "\n",
      "An exception to this pattern is when you're ready to give your final answer. You should insert two markdown subsections (level H3, i.e. `###`) before your final Act line. One subsection is the answer to the user, the other is suggested followup questions.\n",
      "\n",
      "For the answer, you should cite the source you used using markdown footnote, eg [^1] next to the sentence using the source, then give reference at the end: [^1] <Webpage title linking to the webpage, using markdown link>\n",
      "\n",
      "The followup should be a markdown unnumbered list, each question as an item, with nothing else in the subsection.\n",
      "\n",
      "To illustrate, here's an example:\n",
      "...\n",
      "*Observation 5*: ...\n",
      "### Assistent Answer - How to make a cake\n",
      "Here's a quick recipe for **Chocolate cake** [^1]:\n",
      "1. Prepare the flour.\n",
      "2. Put chocolate in the flour.\n",
      "3. Cook in oven at 180C for 30 minutes.\n",
      "----\n",
      "[^1]: [Easy cake recipe - Etsy](https://etsy.com/easy-cake)\n",
      "### Suggested followup to 'how to make a cake'\n",
      "- How to make a pancake?\n",
      "- Where can I buy the ingredient?\n",
      "- How about cookie?\n",
      "*Act 5*: [final_ans(\"Assistent Answer - How to make a cake\", \"Suggested followup to 'how to make a cake'\")].\n",
      "\n",
      "## Input\n",
      "Question: Give me a summary of news on debt ceiling in the US.\n",
      "## Output\n",
      "Assistent: Let's think step by step.\n",
      "*Thought 1*: To find news articles about the debt ceiling in the US, I will use Web Search.\n",
      "*Act 1*: [web_search(\"debt ceiling US news\")].\n",
      "*Observation 1*: Search Result:\n",
      "1. US Government in deadlock over debt ceiling dispute\n",
      "https://cnn.com/news/us/politics/debt-ceiling-5gx7u\n",
      "2. Liberals propose uping the debt ceiling for infrastructural investment, stirs objections from Republican\n",
      "https://realnews.org/liberal-infra-debt/28VeKu\n",
      "3. Are we going to have QE again? Worries loom over recent debt ceiling proposal\n",
      "https://editorial.washingtonpost.com/quince-mac/qe-debt\n",
      "4. Reddit - r/Politics Republican's idea of debt ceiling\n",
      "https://reddit.com/r/politics/republican-idea-debt-ceiling-3JcYhE\n",
      "\n",
      "*Thought 2*: To summarize the news articles, I will read the first and most relevant article which is \"US Government in deadlock over debt ceiling dispute\" from CNN.\n",
      "*Act 2*: [read_webpage(\"https://cnn.com/news/us/politics/debt-ceiling-5gx7u\")].\n",
      "*Observation 2*: Webpage content:\n",
      "The democrats party have proposed a new bill in congress to raise the debt ceiling for an expansionary fiscal policy, investing in the US's infrastructure. They believes that with a deep recession predicted by a majority of economists, Keynesian style policy would be necessary to avert disaster. Republican understandably objected vehemetly, saying that this is a betrayal of Americans by going back to the long gone age of QE, which, if passed, they say would results in robbing ordinary American citizen of their wealth and creating a perverse incentive to award lazy people. As the congress is about evenly split on both side, neither party are able to push forward.\n",
      "\n",
      "*Thought 3*: Therefore, the summary of news articles on debt ceiling in the US is that there is a deadlock between Democrats and Republicans over a proposed bill to raise the debt ceiling for infrastructural investment, with Republicans objecting due to concerns about QE. \n",
      "### Assistent News Summary - Debt Ceiling in US\n",
      "The current situation is characterized by a political impasse between Democrats and Republicans regarding a proposed bill to increase the debt ceiling for infrastructure investment. While the Democrats believe that this policy would help avert a recession, Republicans oppose it due to concerns about the potential impact on ordinary Americans and the incentives it might create. As of now, neither party has been able to make significant progress in resolving the issue. [^1]\n",
      "----\n",
      "[^1]  - CNN: https://cnn.com/news/us/politics/debt-ceiling-5gx7u\n",
      "### Suggested followup\n",
      "- How does the debt ceiling affect the US economy?\n",
      "- What are the potential consequences of not raising the debt ceiling?\n",
      "- How has the debt ceiling been handled in other countries?\n",
      "*Act 3*: [final_ans(\"Assistent News Summary - Debt Ceiling in US\", \"Suggested followup to 'debt ceiling in US'\")].\n"
     ]
    }
   ],
   "source": [
    "print(myOut[\"choices\"][0][\"text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
